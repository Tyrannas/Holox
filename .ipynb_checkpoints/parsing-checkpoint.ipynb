{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Lexems file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  appendFile: [Function: appendFile],\n",
       "  appendFileSync: [Function: appendFileSync],\n",
       "  access: [Function: access],\n",
       "  accessSync: [Function: accessSync],\n",
       "  chown: [Function: chown],\n",
       "  chownSync: [Function: chownSync],\n",
       "  chmod: [Function: chmod],\n",
       "  chmodSync: [Function: chmodSync],\n",
       "  close: [Function: close],\n",
       "  closeSync: [Function: closeSync],\n",
       "  copyFile: [Function: copyFile],\n",
       "  copyFileSync: [Function: copyFileSync],\n",
       "  createReadStream: [Function: createReadStream],\n",
       "  createWriteStream: [Function: createWriteStream],\n",
       "  exists: [Function: exists],\n",
       "  existsSync: [Function: existsSync],\n",
       "  fchown: [Function: fchown],\n",
       "  fchownSync: [Function: fchownSync],\n",
       "  fchmod: [Function: fchmod],\n",
       "  fchmodSync: [Function: fchmodSync],\n",
       "  fdatasync: [Function: fdatasync],\n",
       "  fdatasyncSync: [Function: fdatasyncSync],\n",
       "  fstat: [Function: fstat],\n",
       "  fstatSync: [Function: fstatSync],\n",
       "  fsync: [Function: fsync],\n",
       "  fsyncSync: [Function: fsyncSync],\n",
       "  ftruncate: [Function: ftruncate],\n",
       "  ftruncateSync: [Function: ftruncateSync],\n",
       "  futimes: [Function: futimes],\n",
       "  futimesSync: [Function: futimesSync],\n",
       "  lchown: [Function: lchown],\n",
       "  lchownSync: [Function: lchownSync],\n",
       "  lchmod: undefined,\n",
       "  lchmodSync: undefined,\n",
       "  link: [Function: link],\n",
       "  linkSync: [Function: linkSync],\n",
       "  lstat: [Function: lstat],\n",
       "  lstatSync: [Function: lstatSync],\n",
       "  mkdir: [Function: mkdir],\n",
       "  mkdirSync: [Function: mkdirSync],\n",
       "  mkdtemp: [Function: mkdtemp],\n",
       "  mkdtempSync: [Function: mkdtempSync],\n",
       "  open: [Function: open],\n",
       "  openSync: [Function: openSync],\n",
       "  opendir: [Function: opendir],\n",
       "  opendirSync: [Function: opendirSync],\n",
       "  readdir: [Function: readdir],\n",
       "  readdirSync: [Function: readdirSync],\n",
       "  read: [Function: read],\n",
       "  readSync: [Function: readSync],\n",
       "  readv: [Function: readv],\n",
       "  readvSync: [Function: readvSync],\n",
       "  readFile: [Function: readFile],\n",
       "  readFileSync: [Function: readFileSync],\n",
       "  readlink: [Function: readlink],\n",
       "  readlinkSync: [Function: readlinkSync],\n",
       "  realpath: [Function: realpath] { native: [Function (anonymous)] },\n",
       "  realpathSync: [Function: realpathSync] { native: [Function (anonymous)] },\n",
       "  rename: [Function: rename],\n",
       "  renameSync: [Function: renameSync],\n",
       "  rmdir: [Function: rmdir],\n",
       "  rmdirSync: [Function: rmdirSync],\n",
       "  stat: [Function: stat],\n",
       "  statSync: [Function: statSync],\n",
       "  symlink: [Function: symlink],\n",
       "  symlinkSync: [Function: symlinkSync],\n",
       "  truncate: [Function: truncate],\n",
       "  truncateSync: [Function: truncateSync],\n",
       "  unwatchFile: [Function: unwatchFile],\n",
       "  unlink: [Function: unlink],\n",
       "  unlinkSync: [Function: unlinkSync],\n",
       "  utimes: [Function: utimes],\n",
       "  utimesSync: [Function: utimesSync],\n",
       "  watch: [Function: watch],\n",
       "  watchFile: [Function: watchFile],\n",
       "  writeFile: [Function: writeFile],\n",
       "  writeFileSync: [Function: writeFileSync],\n",
       "  write: [Function: write],\n",
       "  writeSync: [Function: writeSync],\n",
       "  writev: [Function: writev],\n",
       "  writevSync: [Function: writevSync],\n",
       "  Dir: [Function: Dir],\n",
       "  Dirent: [Function: Dirent],\n",
       "  Stats: [Function: Stats],\n",
       "  ReadStream: [Getter/Setter],\n",
       "  WriteStream: [Getter/Setter],\n",
       "  FileReadStream: [Getter/Setter],\n",
       "  FileWriteStream: [Getter/Setter],\n",
       "  _toUnixTimestamp: [Function: toUnixTimestamp],\n",
       "  F_OK: 0,\n",
       "  R_OK: 4,\n",
       "  W_OK: 2,\n",
       "  X_OK: 1,\n",
       "  constants: [Object: null prototype] {\n",
       "    UV_FS_SYMLINK_DIR: 1,\n",
       "    UV_FS_SYMLINK_JUNCTION: 2,\n",
       "    O_RDONLY: 0,\n",
       "    O_WRONLY: 1,\n",
       "    O_RDWR: 2,\n",
       "    UV_DIRENT_UNKNOWN: 0,\n",
       "    UV_DIRENT_FILE: 1,\n",
       "    UV_DIRENT_DIR: 2,\n",
       "    UV_DIRENT_LINK: 3,\n",
       "    UV_DIRENT_FIFO: 4,\n",
       "    UV_DIRENT_SOCKET: 5,\n",
       "    UV_DIRENT_CHAR: 6,\n",
       "    UV_DIRENT_BLOCK: 7,\n",
       "    S_IFMT: 61440,\n",
       "    S_IFREG: 32768,\n",
       "    S_IFDIR: 16384,\n",
       "    S_IFCHR: 8192,\n",
       "    S_IFLNK: 40960,\n",
       "    O_CREAT: 256,\n",
       "    O_EXCL: 1024,\n",
       "    UV_FS_O_FILEMAP: 536870912,\n",
       "    O_TRUNC: 512,\n",
       "    O_APPEND: 8,\n",
       "    F_OK: 0,\n",
       "    R_OK: 4,\n",
       "    W_OK: 2,\n",
       "    X_OK: 1,\n",
       "    UV_FS_COPYFILE_EXCL: 1,\n",
       "    COPYFILE_EXCL: 1,\n",
       "    UV_FS_COPYFILE_FICLONE: 2,\n",
       "    COPYFILE_FICLONE: 2,\n",
       "    UV_FS_COPYFILE_FICLONE_FORCE: 4,\n",
       "    COPYFILE_FICLONE_FORCE: 4\n",
       "  },\n",
       "  promises: [Getter]\n",
       "}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = require('fs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fin_phrase := \\\\.\\r\\n' +\n",
       "  'fin_expression := \\\\,\\r\\n' +\n",
       "  'left_par := \\\\(\\r\\n' +\n",
       "  'right_par := \\\\)\\r\\n' +\n",
       "  'liaison := \\\\+\\r\\n' +\n",
       "  'appartient := _\\r\\n' +\n",
       "  'deco_fort := \\\\*\\\\*\\r\\n' +\n",
       "  'deco_plusieurs := \\\\*\\r\\n' +\n",
       "  'mot := [A-Za-z]+\\r\\n' +\n",
       "  'id := :\\\\d+\\r\\n' +\n",
       "  'ref := @\\\\d+\\r\\n' +\n",
       "  'present_droit := ->\\r\\n' +\n",
       "  'passe_droit := \\\\\\\\>\\r\\n' +\n",
       "  'futur_droit := />\\r\\n' +\n",
       "  'present_gauche := <-\\r\\n' +\n",
       "  'passe_gauche := </\\r\\n' +\n",
       "  'futur_gauche := <\\\\\\\\'"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexer_str = fs.readFileSync('lexems.ho').toString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the lexems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the tokenizer which each regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = {}\n",
    "lexems = lexer_str.split('\\r\\n')\n",
    "lexems.forEach(l => { \n",
    "    let parsed = l.trim().split(':=')\n",
    "    regex = \"^\" + parsed[1].trim()\n",
    "    tokenizer[parsed[0].trim()] = new RegExp(regex)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "function toTokens(phrase){\n",
    "    let tokens = []\n",
    "    for(cursor = 0; cursor < phrase.length; ++cursor){\n",
    "        // ignore spaces\n",
    "        if(phrase[cursor] === \" \"){\n",
    "            continue\n",
    "        }\n",
    "        let found = false\n",
    "        for (let el of Object.entries(tokenizer)){\n",
    "            let regex = el[1]\n",
    "            let tokenName = el[0]\n",
    "            let res = phrase.slice(cursor).match(regex)\n",
    "            if(res){\n",
    "                console.log(\"wow we found a \" + tokenName + \" with value \" + res)\n",
    "                tokens.push({type: tokenName, value: res[0]})\n",
    "                found = true\n",
    "                cursor += res[0].length - 1\n",
    "                break\n",
    "            }\n",
    "        }\n",
    "        if(!found){\n",
    "            console.log(\"arf, could not tokenize character \" + phrase[cursor])\n",
    "        }\n",
    "    }\n",
    "    return tokens\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(Faisan + Multicolore):1 \\\\> Etre -> Oiseau, *Chasseurs* -> (Chasser + Beaucoup) -> @1'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = \"(Faisan + Multicolore):1 \\\\> Etre -> Oiseau, *Chasseurs* -> (Chasser + Beaucoup) -> @1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wow we found a left_par with value (\n",
      "wow we found a mot with value Faisan\n",
      "wow we found a liaison with value +\n",
      "wow we found a mot with value Multicolore\n",
      "wow we found a right_par with value )\n",
      "wow we found a id with value :1\n",
      "wow we found a passe_droit with value \\>\n",
      "wow we found a mot with value Etre\n",
      "wow we found a present_droit with value ->\n",
      "wow we found a mot with value Oiseau\n",
      "wow we found a fin_expression with value ,\n",
      "wow we found a deco_plusieurs with value *\n",
      "wow we found a mot with value Chasseurs\n",
      "wow we found a deco_plusieurs with value *\n",
      "wow we found a present_droit with value ->\n",
      "wow we found a left_par with value (\n",
      "wow we found a mot with value Chasser\n",
      "wow we found a liaison with value +\n",
      "wow we found a mot with value Beaucoup\n",
      "wow we found a right_par with value )\n",
      "wow we found a present_droit with value ->\n",
      "wow we found a ref with value @1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\n",
       "  { type: 'left_par', value: '(' },\n",
       "  { type: 'mot', value: 'Faisan' },\n",
       "  { type: 'liaison', value: '+' },\n",
       "  { type: 'mot', value: 'Multicolore' },\n",
       "  { type: 'right_par', value: ')' },\n",
       "  { type: 'id', value: ':1' },\n",
       "  { type: 'passe_droit', value: '\\\\>' },\n",
       "  { type: 'mot', value: 'Etre' },\n",
       "  { type: 'present_droit', value: '->' },\n",
       "  { type: 'mot', value: 'Oiseau' },\n",
       "  { type: 'fin_expression', value: ',' },\n",
       "  { type: 'deco_plusieurs', value: '*' },\n",
       "  { type: 'mot', value: 'Chasseurs' },\n",
       "  { type: 'deco_plusieurs', value: '*' },\n",
       "  { type: 'present_droit', value: '->' },\n",
       "  { type: 'left_par', value: '(' },\n",
       "  { type: 'mot', value: 'Chasser' },\n",
       "  { type: 'liaison', value: '+' },\n",
       "  { type: 'mot', value: 'Beaucoup' },\n",
       "  { type: 'right_par', value: ')' },\n",
       "  { type: 'present_droit', value: '->' },\n",
       "  { type: 'ref', value: '@1' }\n",
       "]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = toTokens(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'texte      := phrase fin_phrase | texte ;\\r\\n' +\n",
       "  '\\r\\n' +\n",
       "  'phrase     := expression fin_expression \\r\\n' +\n",
       "  '           |  expression \\r\\n' +\n",
       "  '           |  phrase ;\\r\\n' +\n",
       "  '\\r\\n' +\n",
       "  'expression := groupe action groupe action groupe \\r\\n' +\n",
       "  '           |  groupe ;\\r\\n' +\n",
       "  '\\r\\n' +\n",
       "  'groupe      := groupe_mot | groupe_mot id ;\\r\\n' +\n",
       "  '\\r\\n' +\n",
       "  'groupe_mot := noeud_vide |\\r\\n' +\n",
       "  '              noeud_mot |\\r\\n' +\n",
       "  '              left_par noeud_mot right_par |\\r\\n' +\n",
       "  '              left_par noeud_mot liaison_groupe_mot right_par ;\\r\\n' +\n",
       "  '            \\r\\n' +\n",
       "  'liaison_groupe_mot := liaison noeud_mot | liaison_groupe_mot ;\\r\\n' +\n",
       "  '\\r\\n' +\n",
       "  'link_mot   := liaison | appartient ;\\r\\n' +\n",
       "  '\\r\\n' +\n",
       "  'noeud_mot  := deco_mot mot deco_mot | mot | ref ;\\r\\n' +\n",
       "  '\\r\\n' +\n",
       "  'noeud_vide := left_par right_par ;\\r\\n' +\n",
       "  '\\r\\n' +\n",
       "  'deco_mot   := deco_plusieurs | deco_fort ;\\r\\n' +\n",
       "  '\\r\\n' +\n",
       "  'action     := present_gauche | present_droit | passe_gauche | passe_droit | futur_gauche | futur_droit ;'"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar_str = fs.readFileSync('grammar.ho').toString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  'texte      := phrase fin_phrase | texte ',\n",
      "  '\\r\\n' +\n",
      "    '\\r\\n' +\n",
      "    'phrase     := expression fin_expression \\r\\n' +\n",
      "    '           |  expression \\r\\n' +\n",
      "    '           |  phrase ',\n",
      "  '\\r\\n' +\n",
      "    '\\r\\n' +\n",
      "    'expression := groupe action groupe action groupe \\r\\n' +\n",
      "    '           |  groupe ',\n",
      "  '\\r\\n\\r\\ngroupe      := groupe_mot | groupe_mot id ',\n",
      "  '\\r\\n' +\n",
      "    '\\r\\n' +\n",
      "    'groupe_mot := noeud_vide |\\r\\n' +\n",
      "    '              noeud_mot |\\r\\n' +\n",
      "    '              left_par noeud_mot right_par |\\r\\n' +\n",
      "    '              left_par noeud_mot liaison_groupe_mot right_par ',\n",
      "  '\\r\\n' +\n",
      "    '            \\r\\n' +\n",
      "    'liaison_groupe_mot := liaison noeud_mot | liaison_groupe_mot ',\n",
      "  '\\r\\n\\r\\nlink_mot   := liaison | appartient ',\n",
      "  '\\r\\n\\r\\nnoeud_mot  := deco_mot mot deco_mot | mot | ref ',\n",
      "  '\\r\\n\\r\\nnoeud_vide := left_par right_par ',\n",
      "  '\\r\\n\\r\\ndeco_mot   := deco_plusieurs | deco_fort ',\n",
      "  '\\r\\n' +\n",
      "    '\\r\\n' +\n",
      "    'action     := present_gauche | present_droit | passe_gauche | passe_droit | futur_gauche | futur_droit ',\n",
      "  ''\n",
      "]\n",
      "[ 'phrase fin_phrase', 'texte' ]\n",
      "[ 'expression fin_expression', 'expression', 'phrase' ]\n",
      "[ 'groupe action groupe action groupe', 'groupe' ]\n",
      "[ 'groupe_mot', 'groupe_mot id' ]\n",
      "[\n",
      "  'noeud_vide',\n",
      "  'noeud_mot',\n",
      "  'left_par noeud_mot right_par',\n",
      "  'left_par noeud_mot liaison_groupe_mot right_par'\n",
      "]\n",
      "[ 'liaison noeud_mot', 'liaison_groupe_mot' ]\n",
      "[ 'liaison', 'appartient' ]\n",
      "[ 'deco_mot mot deco_mot', 'mot', 'ref' ]\n",
      "[ 'left_par right_par' ]\n",
      "[ 'deco_plusieurs', 'deco_fort' ]\n",
      "[\n",
      "  'present_gauche',\n",
      "  'present_droit',\n",
      "  'passe_gauche',\n",
      "  'passe_droit',\n",
      "  'futur_gauche',\n",
      "  'futur_droit'\n",
      "]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot read property 'split' of undefined",
     "output_type": "error",
     "traceback": [
      "evalmachine.<anonymous>:6",
      "    let tokens = parsed[1].split('|').map(tok => tok.trim())",
      "                           ^",
      "",
      "TypeError: Cannot read property 'split' of undefined",
      "    at evalmachine.<anonymous>:6:28",
      "    at Array.forEach (<anonymous>)",
      "    at evalmachine.<anonymous>:4:7",
      "    at Script.runInThisContext (vm.js:131:18)",
      "    at Object.runInThisContext (vm.js:295:38)",
      "    at run ([eval]:1054:15)",
      "    at onRunRequest ([eval]:888:18)",
      "    at onMessage ([eval]:848:13)",
      "    at process.emit (events.js:315:20)",
      "    at emit (internal/child_process.js:906:12)"
     ]
    }
   ],
   "source": [
    "grammar = {}\n",
    "rules = grammar_str.split(';')\n",
    "console.log(rules)\n",
    "rules.pop()\n",
    "rules.forEach(r => { \n",
    "    let parsed = r.trim().split(':=')\n",
    "    let tokens = parsed[1].split('|').map(tok => tok.trim())\n",
    "    console.log(tokens)\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Javascript (Node.js)",
   "language": "javascript",
   "name": "javascript"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "application/javascript",
   "name": "javascript",
   "version": "14.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
